# Feedback-Prize--English-Language-Learning
3rd-Place-Solution for Feedback-Prize---English-Language-Learning

B. SUBMISSION MODEL
Models should be submitted in a single zip archive that contains all of the items detailed below.

Below are some best practices for documenting and delivering your solution. There may be acceptable variations to these guidelines, depending on the type of competition, code, or methods you used. The core requirement is that you detail all the pieces needed by the host to reproduce your solution with the score your team achieved on the leaderboard within a reasonable margin.

This section is for a technical audience who are trying to run your solution. Please make sure your code is well commented.

B1. All code, data, and your trained model goes in a single archive
Except for data downloaded from Kaggle

Note: If you are preparing documentation for a Kernels Only competition, then please share your kernel with the host by adding their user name as a collaborator. If the winner's license requirement is open source, you can also make your kernel public.

B2. README.md
Create a README.md file at the top level of the archive. Here is an example file. This file concisely and precisely describes the following:

The hardware you used: CPU specs, number of CPU cores, memory, GPU specs, number of GPUs.
OS/platform you used, including version number.
Any necessary 3rd-party software, including version numbers, and installation steps. This can be provided as a Dockerfile instead of as a section in the readme.
How to train your model
How to make predictions on a new test set.
Important side effects of your code. For example, if your data processing code overwrites the original data.
Key assumptions made by your code. For example, if the outputs folder must be empty when starting a training run.
B3. Configuration files
Create a sub-folder with any necessary configuration files, such as `$HOME/.keras/keras.json`. The README should also include a description of what these files are and where they need to be placed to function.

B4. requirements.txt
Create a requirements.txt file at the top level of the archive. Here is an example file. This should specify the exact version of all of the packages used, such as `pandas==0.23.0`. This can be generated with tools like `pip freeze` in Python or `devtools::session_info()` in R. The requirements file can also be replaced with a Dockerfile, as long as the installations all use exact version numbers.

B5. directory_structure.txt
Create a readout of the directory tree at the top level of the archive. Here is an example file. This should be in the format generated by running the Linux command `find . -type d > directory_structure.txt` from the top level of your project folder.

B6. SETTINGS.json
This file specifies the path to the train, test, model, and output directories. Here is an example file.

This is the only place that specifies the path to these directories.
Any code that is doing I/O should use the appropriate base paths from SETTINGS.json
B7. Serialized copy of the trained model
Save a copy of the trained model to disk. This enables code to use the trained model to make predictions on new data points without re-training the model (which is typically much more time-intensive). If model checkpoint files were part of your normal workflow, the README should list the path to the folder you saved them in.

B8. entry_points.md
A list of the commands required to run your code. As a best practice, separate training code from prediction code. For example, if youâ€™re using python, there would be up to three entry points to your code:

python prepare_data.py, which would
Read training data from RAW_DATA_DIR (specified in SETTINGS.json)
Run any preprocessing steps
Save the cleaned data to CLEAN_DATA_DIR (specified in SETTINGS.json)
python train.py, which would
Read training data from TRAIN_DATA_CLEAN_PATH (specified in SETTINGS.json)
Train your model. If checkpoint files are used, specify CHECKPOINT_DIR in SETTINGS.json.
Save your model to MODEL_DIR (specified in SETTINGS.json)
python predict.py, which would
Read test data from TEST_DATA_CLEAN_PATH (specified in SETTINGS.json)
Load your model from MODEL_DIR (specified in SETTINGS.json)
Use your model to make predictions on new samples
Save your predictions to SUBMISSION_DIR (specified in SETTINGS.json)
